version: '3.8'

services:
  chatbot:
    build: .
    container_name: ttyd_chatbot
    restart: always
    ports:
      - "5000:5000"
    volumes:
      - ./instructions.txt:/app/instructions.txt
      - ./my_files:/app/my_files
    env_file:
      - .env
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
          ollama_check_server:
            condition: service_completed_successfully  # ‚úÖ Only start if Ollama check succeeds

  weaviate:
    image: semitechnologies/weaviate:latest
    container_name: weaviate
    restart: always
    ports:
      - "8080:8080"
    environment:
      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true
      - PERSISTENCE_DATA_PATH=/var/lib/weaviate
    depends_on:
          ollama_check_server:
            condition: service_completed_successfully  # ‚úÖ Only start if Ollama check succeeds

  ollama_check_server:
    image: curlimages/curl:latest
    container_name: ollama_check_server
    restart: "no"
    env_file:
      - .env  # ‚úÖ Load Ollama settings from .env
    command: >
      sh -c "
      echo 'üîç Checking Ollama server at ${OLLAMA_SCHEMA}://${OLLAMA_HOST}:${OLLAMA_PORT}...';
      until curl -s --head --request GET '${OLLAMA_SCHEMA}://${OLLAMA_HOST}:${OLLAMA_PORT}' | grep '200 OK'; do
        echo '‚è≥ Waiting for Ollama server...';
        sleep 2;
      done;
      echo '‚úÖ Ollama server is up and running!';
      exit 0;
      "
    healthcheck:
      test: ["CMD", "curl", "-s", "--head", "--request", "GET", "${OLLAMA_SCHEMA}://${OLLAMA_HOST}:${OLLAMA_PORT}"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 5s
    extra_hosts:
      - "host.docker.internal:host-gateway"
version: '3.8'

services:
  chatbot:
    build: .
    container_name: ttyd_chatbot
    restart: always
    ports:
      - "5000:5000"
    volumes:
      - ./instructions.txt:/app/instructions.txt
      - ./my_files:/app/my_files
    environment:
      - OLLAMA_SCHEMA=${OLLAMA_SCHEMA:-http}
      # `host.docker.internal` is a special DNS name required by Docker Desktop on Windows/macOS 
      # to resolve localhost. On Linux, it does not exist by default, so we add `extra_hosts` to 
      # ensure it works. If Ollama runs externally, replace this with its actual IP.
      - OLLAMA_HOST=${OLLAMA_HOST:-host.docker.internal}
      - OLLAMA_PORT=${OLLAMA_PORT:-11434}
      - OLLAMA_TEMPERATURE=${OLLAMA_TEMPERATURE:-0.5}
      - WEAVIATE_HOST=${WEAVIATE_HOST:-weaviate}
      - WEAVIATE_PORT=${WEAVIATE_PORT:-8080}
      - WEAVIATE_ALPHA=${WEAVIATE_ALPHA:-0.5}
      - MODEL_NAME=llama3.2:3b
      - LOCAL_MODEL_NAME=all-MiniLM-L6-v2
    extra_hosts:
      - "host.docker.internal:host-gateway"

  weaviate:
    image: semitechnologies/weaviate:latest
    container_name: weaviate
    restart: always
    ports:
      - "8080:8080"
    environment:
      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true
      - PERSISTENCE_DATA_PATH=/var/lib/weaviate

version: '3.8'

services:
  chatbot:
    build: .
    container_name: ttyd_chatbot
    restart: always
    ports:
      - "5000:5000"
    volumes:
      - ./instructions.txt:/app/instructions.txt
      - ./my_files:/app/my_files
    env_file:
      - .env
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      ollama_check_server:
        condition: service_healthy  # ✅ Ensures Ollama server is reachable before chatbot starts

  weaviate:
    image: semitechnologies/weaviate:latest
    container_name: weaviate
    restart: always
    ports:
      - "8080:8080"
    environment:
      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true
      - PERSISTENCE_DATA_PATH=/var/lib/weaviate

  ollama_check_server:
    image: curlimages/curl:latest
    container_name: ollama_check_server
    restart: "no"
    env_file:
      - .env
    command: >
      sh -c "
      until curl -s --head --request GET '${OLLAMA_SCHEMA}://${OLLAMA_HOST}:${OLLAMA_PORT}' | grep '200 OK'; do
        echo 'Waiting for Ollama server...';
        sleep 2;
      done;
      echo '✅ Ollama server is up and running!';
      exit 0;
      "
    healthcheck:
      test: ["CMD", "curl", "-s", "--head", "--request", "GET", "http://${OLLAMA_HOST}:${OLLAMA_PORT}"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 10s  # ✅ Gives more time for Ollama to start before marking failure
